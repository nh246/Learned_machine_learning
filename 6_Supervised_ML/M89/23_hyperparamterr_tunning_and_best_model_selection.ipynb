{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the best model with Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# train test split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import regression algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#import grid search cv for cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import preprocessors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_bill",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tip",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sex",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "smoker",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "day",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "time",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "size",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4cd44451-22d2-4811-970e-77857a47e279",
       "rows": [
        [
         "0",
         "16.99",
         "1.01",
         "Female",
         "No",
         "Sun",
         "Dinner",
         "2"
        ],
        [
         "1",
         "10.34",
         "1.66",
         "Male",
         "No",
         "Sun",
         "Dinner",
         "3"
        ],
        [
         "2",
         "21.01",
         "3.5",
         "Male",
         "No",
         "Sun",
         "Dinner",
         "3"
        ],
        [
         "3",
         "23.68",
         "3.31",
         "Male",
         "No",
         "Sun",
         "Dinner",
         "2"
        ],
        [
         "4",
         "24.59",
         "3.61",
         "Female",
         "No",
         "Sun",
         "Dinner",
         "4"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rergression Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and variables\n",
    "X = df.drop('tip', axis=1)\n",
    "y = df['tip']\n",
    "\n",
    "# label encode categorical variables\n",
    "le = LabelEncoder()\n",
    "X['sex'] = le.fit_transform(X['sex'])\n",
    "X['smoker'] = le.fit_transform(X['smoker'])\n",
    "X['day'] = le.fit_transform(X['day'])\n",
    "X['time'] = le.fit_transform(X['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error for SVR is  0.57\n",
      "Mean Absolute error for LinearRegression is  0.67\n",
      "Mean Absolute error for GradientBoostingRegressor is  0.73\n",
      "Mean Absolute error for KNeighborsRegressor is  0.73\n",
      "Mean Absolute error for RandomForestRegressor is  0.77\n",
      "Mean Absolute error for XGBRegressor is  0.80\n",
      "Mean Absolute error for DecisionTreeRegressor is  0.91\n",
      "CPU times: total: 469 ms\n",
      "Wall time: 670 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = mean_absolute_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('Mean Absolute error for', f\"{model[0]} is {model[1]: .2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared Score SVR is  0.57\n",
      "R_squared Score LinearRegression is  0.44\n",
      "R_squared Score GradientBoostingRegressor is  0.36\n",
      "R_squared Score KNeighborsRegressor is  0.33\n",
      "R_squared Score XGBRegressor is  0.23\n",
      "R_squared Score RandomForestRegressor is  0.22\n",
      "R_squared Score DecisionTreeRegressor is -0.23\n",
      "CPU times: total: 375 ms\n",
      "Wall time: 485 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = r2_score(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=True)\n",
    "for model in sorted_models:\n",
    "    print('R_squared Score', f\"{model[0]} is {model[1]: .2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared error for SVR is  0.54\n",
      "Mean Squared error for LinearRegression is  0.69\n",
      "Mean Squared error for GradientBoostingRegressor is  0.81\n",
      "Mean Squared error for KNeighborsRegressor is  0.84\n",
      "Mean Squared error for RandomForestRegressor is  0.90\n",
      "Mean Squared error for XGBRegressor is  0.96\n",
      "Mean Squared error for DecisionTreeRegressor is  1.32\n",
      "CPU times: total: 344 ms\n",
      "Wall time: 504 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = mean_squared_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('Mean Squared error for', f\"{model[0]} is {model[1]: .2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset('diamonds')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE:  0.6948129686287711\n",
      "LinearRegression R2:  0.4441368826121931\n",
      "LinearRegression MAE:  0.6703807496461157\n",
      "\n",
      "\n",
      "SVR MSE:  1.460718141299992\n",
      "SVR R2:  -0.1686013018011976\n",
      "SVR MAE:  0.8935334948775431\n",
      "\n",
      "\n",
      "DecisionTreeRegressor MSE:  0.8774153020453991\n",
      "DecisionTreeRegressor R2:  0.2980516670532911\n",
      "DecisionTreeRegressor MAE:  0.7189481629481629\n",
      "\n",
      "\n",
      "RandomForestRegressor MSE:  0.9813709430612259\n",
      "RandomForestRegressor R2:  0.2148852477517842\n",
      "RandomForestRegressor MAE:  0.7909081632653062\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CONDA_ENVS\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:131: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"e:\\CONDA_ENVS\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 255, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor MSE:  0.6640950568462677\n",
      "KNeighborsRegressor R2:  0.4687117753876745\n",
      "KNeighborsRegressor MAE:  0.6203721488595437\n",
      "\n",
      "\n",
      "GradientBoostingRegressor MSE:  0.8106801524004932\n",
      "GradientBoostingRegressor R2:  0.35144101065487676\n",
      "GradientBoostingRegressor MAE:  0.7657809818712309\n",
      "\n",
      "\n",
      "XGBRegressor MSE:  0.876761090898943\n",
      "XGBRegressor R2:  0.2985750479683259\n",
      "XGBRegressor MAE:  0.7470519764569341\n",
      "\n",
      "\n",
      "CPU times: total: 4.2 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid']}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(), {'max_depth': [None, 5, 10]}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(), {'n_estimators': [10, 100]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2)}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'n_estimators': [10, 100]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline\n",
    "    pipeline = GridSearchCV(model, params, cv=5)\n",
    "    \n",
    "    # fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "      \n",
    "    # print the performing metric\n",
    "    print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE:  0.6948129686287711\n",
      "LinearRegression R2:  0.4441368826121931\n",
      "LinearRegression MAE:  0.6703807496461157\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'epsilon': [0.1, 0.01, 0.001]}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(), {'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2), 'weights': ['uniform', 'distance']}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': [10, 100, 1000]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100, 1000], 'learning_rate': [0.1, 0.01, 0.001]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline\n",
    "    pipeline = GridSearchCV(model, params, cv=5)\n",
    "    \n",
    "    # fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "      \n",
    "    # print the performing metric\n",
    "    print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Add preprocessor inside the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# make a preprocessor\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Note: transformers must be a list of tuples: (name, transformer, columns)\u001b[39;00m\n\u001b[32m      5\u001b[39m preprocessor = ColumnTransformer(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     transformers=[(\u001b[33m'\u001b[39m\u001b[33mnumeric_scaling\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mStandardScaler\u001b[49m(), [\u001b[33m'\u001b[39m\u001b[33mtotal_bill\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m])],\n\u001b[32m      7\u001b[39m     remainder=\u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create a dictionaries of list of models to evaluate performance with hyperparameters\u001b[39;00m\n\u001b[32m     12\u001b[39m models = { \n\u001b[32m     13\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mLinearRegression\u001b[39m\u001b[33m'\u001b[39m : (LinearRegression(), {}),\n\u001b[32m     14\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mSVR\u001b[39m\u001b[33m'\u001b[39m : (SVR(), {\u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mrbf\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpoly\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m0.1\u001b[39m, \u001b[32m0.01\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mepsilon\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m0.01\u001b[39m, \u001b[32m0.001\u001b[39m]}),\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mXGBRegressor\u001b[39m\u001b[33m'\u001b[39m : (XGBRegressor(), {\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m10\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m1000\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m0.01\u001b[39m, \u001b[32m0.001\u001b[39m]}),          \n\u001b[32m     20\u001b[39m           }\n",
      "\u001b[31mNameError\u001b[39m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# make a preprocessor\n",
    "# Note: transformers must be a list of tuples: (name, transformer, columns)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('numeric_scaling', StandardScaler(), ['total_bill', 'size'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "# Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'epsilon': [0.1, 0.01, 0.001]}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(), {'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2), 'weights': ['uniform', 'distance']}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': [10, 100, 1000]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100, 1000], 'learning_rate': [0.1, 0.01, 0.001]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipeline with preprocessor\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])   \n",
    "    \n",
    "    # GridSearch over pipeline requires parameter names to target the estimator step,\n",
    "    # so prefix model hyperparameters with \"model__\"\n",
    "    params_prefixed = {f\"model__{k}\": v for k, v in params.items()}\n",
    "    \n",
    "    # make a grid search cv to tune the hyperparameter\n",
    "    grid_search = GridSearchCV(pipeline, params_prefixed, cv=5)\n",
    "    \n",
    "    # fit the pipeline\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # print the performing metric\n",
    "    print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Mean Accuracy: 0.9533333333333335\n",
      "\n",
      "Classifier: Random Forest\n",
      "Mean Accuracy: 0.9600000000000002\n",
      "\n",
      "Classifier: SVM\n",
      "Mean Accuracy: 0.9666666666666668\n",
      "\n",
      "Classifier: KNN\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# dont show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a dictionary of classifiers to evaluate\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Perform k-fold cross-validation and calculate the mean accuracy\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold)\n",
    "    accuracy = np.mean(scores)\n",
    "    print(\"Classifier:\", name)\n",
    "    print(\"Mean Accuracy:\", accuracy)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
